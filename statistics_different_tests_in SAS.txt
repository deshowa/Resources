IQ#### This is a running log of the types of tests used in SAS and their applications####


5 general assumptions about data to run tests:
	1.) normally distributed
	2.) independent observations
	3.) quantitative data
	4.) data come from a randomly drawn sample
	5.) the data are representative of the population
	6.) technically for 2 sample tests - population standard deviations are equal
	## with multiple comparison tests sample size sb about the same

## must load the data; several ways to to so
	# first: manual input:
	data brakes;
	input standard new;  # note that test variables must be entered followed by $
	datalines;
	[data]
	;

	# second: read in local file
	data incomes;
	infile '\\Client\C$\SMU Data Science\Statistics 1\datasets\CSV\ex0525.csv' firstobs = 2 dlm = ',';
	input subject education$ income2005;
	run;
	
	# third: Use the file command to import data


## first things we do are look at boxplots, qqplots, and histograms in SAS## (note that in SAS one of the tests puts line through QQplot)- note to come back to this

	# sometimes, need to sort data first if have multiple samples/treatments
	proc sort data = incomes;
	key education  income2005 /ascending; # the key argument is what you are sorting by and allows for multi-level sort
	run;


	# histogram #
	proc univariate data = heights;
	by sport;
	histogram height;
	run;

	# boxplot #
	
	proc boxplot data = height;
	plot height*sport; # quantitative value always comes before the qualitative dimension in the boxplot
	run;

	# QQplots of the data
	proc univariate data = incomes;
	class education;
	var income2005;
	qqplot;

	# 5 number summary in SAS
	proc means data = height n mean min q1 median q3 max std order = data  # only order if not sorted yet
	run;

	# 5 number summary more in depth  # notice that we added the by argument here
	proc means data = incomes n mean min q1 median q3 max std order = data ;
	by education;
	var income2005;
	run;

## After looking at the data, we are ready to run our tests, of which we have a menu:

	Sometimes, you will want to filter data for values prior to a test for the case of interest
	
		DATA scores2;
 		 SET scores;
 		 IF (race = 1) OR (race = 4);
		run;


## Welch's t-test: for testing a hypothesis of the mean

	# one sample t-test with hypothesized mean (assumed normal and all assumptions met)

	proc ttest data = IQ sides = (U,L,2) Ho = 117;
	var score # telling the test what we are testing for the hypothesis
	run;

	# 2 sample t-test for unequal means
	
	proc ttest data = brakes sides = u  # could be any, but from brake lights example
	var times; # quatitative variable
	class light; # treatment group
	run;
	
	# 2 sample paired t-test # remember that data must be entered a certain way for this to work (can get SAS to calculate diffs)
	
	proc ttest data = brakes ;
	paired standard*new; # can also just create teh column for the diffs
	run;

## In some cases, our data may not meet the assumptions and we may have to do a transformation
	### signs for transformation necessary:
		1.) heavy tails in the dataset
		2.) ratio of smallest to largest measurement is >10
		3.) graphical displays of skewness
		4.) The group with the > mean has the > spread
		5.) non-constant variance (heteroskedsticity)
		6.) ratio of standard deviations (s1/s2) very different from 1 and smaller sample comes from pupulation with the greater standard deviation
	# Remember, at the end of a log transformed test, you must change everything back to your original units
	# Also, remember that you are no longer testing the mean, but rather the ratio of medians ln(Ma/Mb); for CI, want to see if range encompasses 1 (same as containing zero in range)
	# to transform back (depending on log base used) e^value
	## DATA MUST BE POSITIVE/NOT LEFT SKEWED FOR LOG TRANSFORMATION!!!!!!!!!!
	# other transformations do exist : square_root, inverse, reciprocal

	# t-test with log transform reversal built in
	
	proc ttest data = heights dist = lognormal;
	var heights;
	run;

	# to create a log transform column  ******ALWAYS CHECK FOR NEGATIVE NUMBERS OR LEFT SKEW IN YOUR DATASET!!!!! CANNOT TAKE THE LOG OF THESE******

	Data IQIncome; *name new dataset.  I am overwriting the old one;
	set IQIncome; *tell it to start with the old dataset;
	logIncome = log(Income); *add a new variable to the dataset;
	run;

## In other cases, data may not allow for parametric tests:
	1.) data too skewed or very bad outliers
	2.) not enough observations
	3.) violation of variance assumptions (equality and evenly distributed residuals)
	4.) unknown values or ties exist in the dataset - censored, only know data is above or below a certain value

## Non-parametric tests
	
	# Wilcoxon Rank Sum test
		For 2 sample situation
		Good for outliers that cannot be fixed wit hlog transform
		If know data points are greatest or least but dont have accurate measures
	
	proc npar1way data = scores wilcoxon;
	var math;
	class schtyp;
	exact wilcoxon / mc; * for exact p-values and mc tels sas to estimate permuatations because of large dataset; monte carlo
	run;
	
	# Multiple samples (>2) Kruskal Wallace test for Multiple Independent nonparametric samples
	
	proc npar1way data = scores wilcoxon;
	var math;
	class ses; # this variable now just has 3 groups
	exact wilcoxon / mc; * for exact p-values and mc tels sas to estimate permuatations because of large dataset;
	run;
	
	# Wilcoxon Signed Rank test: for non-parametric paired data
		## If you want ot test whether median is different from some value, you would subtract that value from all of your observations, then perform the test.
	
	Can create diff column on read in with:
	data plants;
	input cross shelf;
	diff = cross-shelf;
	datalines;
	[data]
	;
	
	proc univariate data = plants;
	var diff;
	histogram;
	boxplot;
	run;
	
	# Sign test: remember just sums positive values: would use for situation where just know direction of the data; not a powerful test; if data is not quantified; LAST RESORT!!
	
	proc univariate data = plants;
	var diff;
	histogram;
	boxplot;
	run;

	# We may also want to try a permutation test which creates all possible combinations of the datasets

	PROC NPAR1WAY SCORES=DATA DATA=SPOCK;
	VAR PERCENT;
	CLASS JUDGE;
	EXACT SCORES=DATA / MC seed = 25071945;
	TITLE 'Permutation Test (all judges have separate means)';
	run;

## Tests of > 2 means

	To illustrate, we will use the Spock's trial data

DATA SPOCK;
INPUT PERCENT JUDGE $;
IF JUDGE = "Spock's" THEN SPOCKS='Yes';
ELSE SPOCKS= 'No';
INFILE DATALINES DELIMITER='	'; 
DATALINES;
6.4	Spock's
8.7	Spock's
13.3	Spock's
13.6	Spock's
15.0	Spock's
15.2	Spock's
17.7	Spock's
18.6	Spock's
23.1	Spock's
16.8	A
30.8	A
33.6	A
40.5	A
48.9	A
27.0	B
28.9	B
32.0	B
32.7	B
35.5	B
45.6	B
21.0	C
23.4	C
27.5	C
27.5	C
30.5	C
31.9	C
32.5	C
33.8	C
33.8	C
24.3	D
29.7	D
17.7	E
19.7	E
21.5	E
27.9	E
34.8	E
40.2	E
16.5	F
20.7	F
23.5	F
26.4	F
26.7	F
29.5	F
29.8	F
31.9	F
36.2	F
;
RUN;

We already saw that the kruskall wallace provides a non parametric test for >2 means.  However, the ANOVA is the parametric version
All of the same assumptions apply includeing the caveat that samples must be independent of eachother in addition to observations being independent of one another.

# remember to always go run your tests prior to running the ANOVA
	
	PROC MEANS DATA=SPOCK;
	VAR PERCENT;
	CLASS JUDGE;
	TITLE 'Descriptive Statistics for Spock Trial Data';
	RUN;

	# ANOVA test
	PROC GLM DATA=SPOCK PLOTS(UNPACK)=(DIAGNOSTICS RESIDUALS); * we can sctually leave the plots argument off for an anova; however, this will give us residual plots, etc.  This can actually negate the need to run tests bc you cna look at plots
	CLASS JUDGE;
	MODEL PERCENT = JUDGE;
	TITLE 'ANOVA (All judges have separate means)'; 
	RUN; QUIT;

	# sometimes, you may want to run the model against others without using a contrast, this code is a workaround for that
	
	# Reduced Model
	PROC GLM DATA=SPOCK;
	CLASS SPOCKS JUDGE;
	MODEL PERCENT = SPOCKS JUDGE; *put reduced model variable first;
	TITLE 'ANOVA (with reduced model work-around)';
	RUN; QUIT;

	*Kruskal-Wallis Test - ANOVA with ranks; all judges have their own medians (not means, since we are using ranks);
	PROC NPAR1WAY WILCOXON DATA=SPOCK;
	VAR PERCENT;
	CLASS JUDGE;
	EXACT WILCOXON / MC SEED = 9011957;
	TITLE 'Kruskal-Wallis Test (all judges have separate medians)';
	RUN;

	* Permutation test (all judges have their own mean)  - this is testing hte original hypothesis that all means are equal

	*Permutation Test (all judges have their own mean);

	PROC NPAR1WAY SCORES=DATA DATA=SPOCK;
	VAR PERCENT;
	CLASS JUDGE;
	EXACT SCORES=DATA / MC seed = 25071945;
	TITLE 'Permutation Test (all judges have separate means)';
	RUN;


####POST HOC tests (Post ANOVA) - we may have some idea of types of comparisons that we want to make after the fact	

	# we may want to run contrasts to test for either a group together versus the mean or one group in partiular being different (same others equal model). Vey useful!

	PROC GLM DATA=SPOCK;
	CLASS JUDGE;
	MODEL PERCENT=JUDGE;
	CONTRAST "Spock's vs. Others" JUDGE  1 1 1 1 1 1 -6;
	ESTIMATE "Spock's vs. Others" JUDGE  1 1 1 1 1 1 -6 / divisor = 6; * need to figure out what the estimate row is for in the output...not sure
	RUN; QUIT;

	# we can also run the other tests all at once: Bonferroni, tukey, Dunnett, regwq

	proc glm data = SPOCK;
	class judge;
	model percent = judge;
	means judge / bon tukey regwq dunnett("Spock's");
	run;

	# for Tukey with different means, can coax to not give you confidence intervals

	PROC GLM DATA=SPOCK;
	CLASS JUDGE;
	MODEL PERCENT=JUDGE;
	MEANS JUDGE / TUKEY LINES; *Substitute CLDIFF for LINES if you need simultaneous CIs (or use both if you want both);
	RUN; QUIT;

	

### Sometimes in testing we may need to model out random effects (vs. fixed effects).  In this case, we would need to account for that with proc mixed

	# Using fermentation data to run the test

	data ferment;
	input batch process$ response @@ ;
	datalines ;

	1	F1	84	2	F1	79	3	F1	76	4	F1	82	5	F1	74
	1	F2	83	2	F2	72	3	F2	82	4	F2	97	5	F2	76
	1	F3	92	2	F3	87	3	F3	82	4	F3	84	5	F3	75
	1	F4	89	2	F4	74	3	F4	80	4	F4	79	5	F4	83
	;
	proc print data = ferment; run;




	# Random model
	proc mixed data = ferment;
	class batch process; * 2 factors random then fixed;
	model response = process;
	random batch;
	lsmeans process / adjust = tukey pdiff;
	run;


########################## REGRESSION MODELS ###############################################

When running regressions the code is pretty simple.  We can use proc reg to get most of the information we need in order to tell if a regression is a good model.



### Scatterplot - just to highlight how proc gplot can be used 

	data birds;
	infile '\\Client\C$\SMU Data Science\Statistics 1\post session assignments\Unit 10\ex0727.csv' firstobs = 2 dlm = ',';
	input mass tcell;
	run;
	
	symbol value = dot color = blue;
	proc gplot data = birds; 
	plot tcell * mass;
	run;


	

### Simple Linear Regression- simple linear model using the dataset from above

	proc reg data = birds; 
	id Mass; * putting id in will show the value for the input in the columns in the R/CLB/CLI/CLM arguments
	model tcell = mass/ R CLB CLI CLM ; run; 


	"/" arguments
	* R - gives the values of the residuals in a table above the residual plots
	* CLB - gives confidence intervals for slope and intercept
	* CLI - gives prediction intervals for each observation in table
	* CLM - gives confidence intervals for each observation in table

	### In some cases, we may want to calculate the confidence and prediction intervals for a new value of the variable.  In order to do this, we need to input new data into our dataset

	### step 1: create desired values

		data birds2;
		input mass;
		datalines;
		4
		6.475
		run;

	### step 2: add the original data to the new dataset
		
		data birds2;
		set birds birds2;
		run;

	### step 3: run the regression on the new dataset

		proc reg data = birds2;
		id mass;
		model tcell = mass/ R CLB CLI CLM; run;

	### SAS will calculate the prediction and confidence intervals for the user in the table of CLI and CLB values


### Simple Linear Regression- Calibration Problems
	
	# We may want to predict a high cost/low accuracy value from a low cost/high accuracy value (basically predict the x value given a y target value) the following details how to calculate the PI and CI from that information

     CONFIDENCE INTERVAL ( with example data)

	# First: solve for X for the desired Y (6.475 comes from a Y of .3 above)
	# Second: repeat steps 1-3
	# Third: in the regression output: retrieve the Std error for the for the value in question (0.0193) and the slope of the regression line (0.03282)
	# Fourth: calculate the se(calibration inverval) = std error/ slope = 0.0193/0.03282 = 0.58806
	# Fifth: find T = n-2 df; alpha/2 = 2.093
	# sixth: X +/- T*SE(ci) = 6.47 +/- 2.093*0.58806

    PREDICTION INVERVAL
	# First: SE (predi) = srqt(s_hat^2 * std_error^2) =  sqrt(0.08102^2*0.0193^2) = .08329
		s hat - root MSE in regression
		std error same as one in CI
	# second: SEPI(xhat) = SE/slope = .08329/0.03282 = 2.53
	# third: X +/- T*SE(ci) = 6.47 +/- 2.093*2.53


### Simple linear regression- lack of fit f-test
	# After running a simple linear regression model, oftentimes, we need to test whether the model accurately/sufficiently captures all of the variability in the model.  
	# to do this, we can run the lack of fit F-test.  We compare the additional variation explained by ANOVA (on repeat observations of X in the data) versus the simple linear model
	# Ho : Model is a good fit
	# Ha : Model does not explain enough of hte variation in the data

	# step 1: run a simple linear regression
	
	data conc;
	infile '\\Client\C$\SMU Data Science\Statistics 1\post session assignments\Unit 11\concentration.csv' firstobs = 2 dlm = ',';
	input time conc;
	run ;

	proc print data = conc; run ;

	proc reg data = conc;
	model conc = time /R CLM CLB CLI;
	run ; 

	

	# step 2: run proc GLM (ANOVA) on the dataset
	
	proc glm data = conc
	
	class  time;
	model conc = time; run ; quit;

	[(SSE(anova) - SSE(lm))/df(anova)-df(lm)]/[SSE(lm)/df(lm)] =F

	Calculate P- use calculator online: numerator df = subtraction in numerator; denomiator df df of error in partial model
	
	

	





#### MULTIPLE LINEAR REGRESSION #####


### Scatterplot matrix- sometimes we want to take a look at all of the variables versus eachother to determine is there is any collinearity

	Data ex1217;
	infile "\\Client\C$\SMU Data science\Statistics 1\datasets\csv\ex1217.csv" dlm="," dsd firstobs=2;
	format City $20.;
	input City $ Mortality Precip Humidity JanTemp JulyTemp Over65 House Educ Sound Density NonWhite WhiteCol Poor HC NOX SO2;
	run;

	proc print data = ex1217; run;
	proc sgscatter data = ex1217;
	matrix Mortality HC NOX SO2;
	run;
			


	
		

		

	
	


   


	

	



	








